{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 7- Starter code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(5)\n",
    "print y\n",
    "y_hat = y\n",
    "metrics.mean_squared_error(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = y[::-1]\n",
    "print y_hat\n",
    "metrics.mean_squared_error(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample data and fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': range(100), 'y': range(100)})\n",
    "biased_df  = df.copy()\n",
    "biased_df.loc[:20, 'x'] = 1\n",
    "biased_df.loc[:20, 'y'] = 1\n",
    "\n",
    "def append_jitter(series):\n",
    "    jitter = np.random.random_sample(size=100)\n",
    "    return series + jitter\n",
    "\n",
    "df['x'] = append_jitter(df.x)\n",
    "df['y'] = append_jitter(df.y)\n",
    "\n",
    "biased_df['x'] = append_jitter(biased_df.x)\n",
    "biased_df['y'] = append_jitter(biased_df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16602718000795316"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit:\n",
    "lm = linear_model.LinearRegression().fit(df[['x']], df['y'])\n",
    "metrics.mean_squared_error(df['y'], lm.predict(df[['x']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1673954533998657"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## biased fit\n",
    "lm = linear_model.LinearRegression().fit(biased_df[['x']], biased_df['y'])\n",
    "metrics.mean_squared_error(df['y'], lm.predict(df[['x']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "#### Intro to cross validation with bike share data from last time. We will be modeling casual ridership. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "bikeshare = pd.read_csv(join('..', 'data', 'bikeshare.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy variables and set outcome (dependent) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = pd.get_dummies(bikeshare.weathersit, prefix='weather')\n",
    "modeldata = bikeshare[['temp', 'hum']].join(weather[['weather_1', 'weather_2', 'weather_3']])\n",
    "y = bikeshare.casual "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a cross valiation with 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of MSE for 3 folds: 1817.58711453\n",
      "Mean of MSE for 5 folds: 1780.97924083\n",
      "Mean of MSE for 7 folds: 1736.12757027\n",
      "Mean of MSE for 9 folds: 1737.87152693\n",
      "Mean of MSE for 11 folds: 1727.55234543\n",
      "Mean of MSE for 13 folds: 1720.22017285\n",
      "Mean of MSE for 15 folds: 1729.15209047\n",
      "Mean of MSE for 17 folds: 1711.62322766\n",
      "Mean of MSE for 19 folds: 1714.26252611\n",
      "Mean of MSE for 21 folds: 1709.58321257\n",
      "Mean of MSE for 23 folds: 1709.01858956\n",
      "Mean of MSE for 25 folds: 1704.95746641\n",
      "Mean of MSE for 27 folds: 1706.9394101\n",
      "Mean of MSE for 29 folds: 1700.56093245\n",
      "Mean of MSE for 31 folds: 1703.95350075\n",
      "Mean of MSE for 33 folds: 1699.96360776\n",
      "Mean of MSE for 35 folds: 1700.15087471\n",
      "Mean of MSE for 37 folds: 1699.75311293\n",
      "Mean of MSE for 39 folds: 1696.00994702\n",
      "Mean of MSE for 41 folds: 1697.25567268\n",
      "Mean of MSE for 43 folds: 1695.44395904\n",
      "Mean of MSE for 45 folds: 1697.47257937\n",
      "Mean of MSE for 47 folds: 1692.71889465\n",
      "Mean of MSE for 49 folds: 1692.5080456\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAFqCAYAAACgZtiwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC24PmOn6SQg0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114478310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_avg = {}\n",
    "for n_folds in range(3, 50, 2):\n",
    "    kf = cross_validation.KFold(len(modeldata), n_folds=n_folds, shuffle=False)\n",
    "    mse_values = []\n",
    "    scores = []\n",
    "    n= 0\n",
    "#     print \"~~~~ CROSS VALIDATION each fold ~~~~\"\n",
    "    for train_index, test_index in kf:\n",
    "        lm = linear_model.LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "        mse_values.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "        scores.append(lm.score(modeldata, y))\n",
    "        n+=1\n",
    "#         print 'Model', n\n",
    "#         print 'MSE:', mse_values[n-1]\n",
    "#         print 'R2:', scores[n-1]\n",
    "\n",
    "\n",
    "#     print \"~~~~ SUMMARY OF CROSS VALIDATION ~~~~\"\n",
    "    mse_avg[n_folds] = np.mean(mse_values)\n",
    "    print 'Mean of MSE for {} folds:'.format(n_folds), np.mean(mse_values)\n",
    "#     print 'Mean of R2 for all folds:', np.mean(scores)\n",
    "pd.Series(mse_avg).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ Single Model ~~~~\n",
      "MSE of single model: 1672.58110765\n",
      "R2:  0.311934605989\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print \"~~~~ Single Model ~~~~\"\n",
    "print 'MSE of single model:', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'R2: ', lm.score(modeldata, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check\n",
    "While the cross validated approach here generated more overall error, which of the two approaches would predict new data more accurately: the single model or the cross validated, averaged one? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are ways to improve our model with regularization. \n",
    "Let's check out the effects on MSE and R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ OLS ~~~\n",
      "OLS MSE:  1672.58110765\n",
      "OLS R2: 0.311934605989\n",
      "~~~ Lasso ~~~\n",
      "Lasso MSE:  1725.41581608\n",
      "Lasso R2: 0.290199495922\n",
      "~~~ Ridge ~~~\n",
      "Ridge MSE:  1672.60490113\n",
      "Ridge R2: 0.311924817843\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print \"~~~ OLS ~~~\"\n",
    "print 'OLS MSE: ', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'OLS R2:', lm.score(modeldata, y)\n",
    "\n",
    "lm = linear_model.Lasso().fit(modeldata, y)\n",
    "print \"~~~ Lasso ~~~\"\n",
    "print 'Lasso MSE: ', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'Lasso R2:', lm.score(modeldata, y)\n",
    "\n",
    "lm = linear_model.Ridge().fit(modeldata, y)\n",
    "print \"~~~ Ridge ~~~\"\n",
    "print 'Ridge MSE: ', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'Ridge R2:', lm.score(modeldata, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out the alphas can be done by \"hand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-10   1.00000000e-09   1.00000000e-08   1.00000000e-07\n",
      "   1.00000000e-06   1.00000000e-05   1.00000000e-04   1.00000000e-03\n",
      "   1.00000000e-02   1.00000000e-01   1.00000000e+00   1.00000000e+01\n",
      "   1.00000000e+02   1.00000000e+03   1.00000000e+04   1.00000000e+05\n",
      "   1.00000000e+06   1.00000000e+07   1.00000000e+08   1.00000000e+09\n",
      "   1.00000000e+10]\n",
      "Alpha: 1e-10\n",
      "[ 112.68901765  -84.01121684  -24.68489063  -21.00314493  -21.71893628]\n",
      "1672.58110765\n",
      "Alpha: 1e-09\n",
      "[ 112.68901765  -84.01121684  -24.6848906   -21.00314491  -21.71893626]\n",
      "1672.58110765\n",
      "Alpha: 1e-08\n",
      "[ 112.68901765  -84.01121684  -24.6848904   -21.00314471  -21.71893606]\n",
      "1672.58110765\n",
      "Alpha: 1e-07\n",
      "[ 112.68901763  -84.01121682  -24.68488837  -21.00314268  -21.71893403]\n",
      "1672.58110765\n",
      "Alpha: 1e-06\n",
      "[ 112.68901745  -84.01121667  -24.68486804  -21.00312237  -21.71891373]\n",
      "1672.58110765\n",
      "Alpha: 1e-05\n",
      "[ 112.68901562  -84.01121509  -24.68466472  -21.00291929  -21.71871079]\n",
      "1672.58110765\n",
      "Alpha: 0.0001\n",
      "[ 112.68899732  -84.01119938  -24.68263174  -21.00088873  -21.71668161]\n",
      "1672.58110765\n",
      "Alpha: 0.001\n",
      "[ 112.68881437  -84.01104228  -24.66232204  -20.98060316  -21.69640993]\n",
      "1672.58110774\n",
      "Alpha: 0.01\n",
      "[ 112.68698753  -84.00947323  -24.46121539  -20.77973778  -21.49568404]\n",
      "1672.58111645\n",
      "Alpha: 0.1\n",
      "[ 112.66896732  -83.99396383  -22.63109556  -18.95202277  -19.66942371]\n",
      "1672.58185208\n",
      "Alpha: 1.0\n",
      "[ 112.50129738  -83.84805622  -13.38214934   -9.72671278  -10.46162477]\n",
      "1672.60490113\n",
      "Alpha: 10.0\n",
      "[ 110.96062533  -82.49604961   -3.94431741   -0.51765034   -1.45024412]\n",
      "1672.83347262\n",
      "Alpha: 100.0\n",
      "[ 97.69060562 -71.17602377  -0.31585194   1.18284675  -1.33281591]\n",
      "1686.31830362\n",
      "Alpha: 1000.0\n",
      "[ 44.59923075 -30.85843772   5.07876321   0.05369643  -5.107457  ]\n",
      "1937.81576044\n",
      "Alpha: 10000.0\n",
      "[ 7.03007064 -5.07733082  3.29039029 -1.2136063  -2.06842808]\n",
      "2314.83675678\n",
      "Alpha: 100000.0\n",
      "[ 0.75195708 -0.56490872  0.52067881 -0.25075496 -0.26895254]\n",
      "2415.77806566\n",
      "Alpha: 1000000.0\n",
      "[ 0.07576571 -0.05727511  0.05520142 -0.0273591  -0.02774349]\n",
      "2429.28026459\n",
      "Alpha: 10000000.0\n",
      "[ 0.00758239 -0.00573569  0.0055535  -0.00276043 -0.00278317]\n",
      "2430.68891798\n",
      "Alpha: 100000000.0\n",
      "[ 0.0007583  -0.00057365  0.00055569 -0.00027629 -0.00027841]\n",
      "2430.83041212\n",
      "Alpha: 1000000000.0\n",
      "[  7.58303020e-05  -5.73659720e-05   5.55719458e-05  -2.76314619e-05\n",
      "  -2.78414555e-05]\n",
      "2430.84456787\n",
      "Alpha: 10000000000.0\n",
      "[  7.58303603e-06  -5.73660542e-06   5.55722818e-06  -2.76317091e-06\n",
      "  -2.78415441e-06]\n",
      "2430.84598351\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-10, 10, 21)\n",
    "print alphas\n",
    "for a in alphas:\n",
    "    print 'Alpha:', a\n",
    "    lm = linear_model.Ridge(alpha=a)\n",
    "    lm.fit(modeldata, y)\n",
    "    print lm.coef_\n",
    "    print metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or we can use grid search to make this faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-10,   1.00000e-09,   1.00000e-08,   1.00000e-07,\n",
       "         1.00000e-06,   1.00000e-05,   1.00000e-04,   1.00000e-03,\n",
       "         1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02,   1.00000e+03,   1.00000e+04,   1.00000e+05,\n",
       "         1.00000e+06,   1.00000e+07,   1.00000e+08,   1.00000e+09,\n",
       "         1.00000e+10]), 'fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "\n",
    "alphas = np.logspace(-10, 10, 21)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    cv=5,\n",
    "    estimator=linear_model.Ridge(),\n",
    "    param_grid={'alpha': alphas, 'fit_intercept': [True, False]},\n",
    "    scoring='neg_mean_squared_error')\n",
    "\n",
    "gs.fit(modeldata, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1777.68141688\n"
     ]
    }
   ],
   "source": [
    "print gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mean squared error here comes in negative, so let's make it positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1777.68141688\n"
     ]
    }
   ],
   "source": [
    "print -gs.best_score_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### explains which grid_search setup worked best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=10.0, copy_X=True, fit_intercept=False, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "print gs.best_estimator_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### shows all the grid pairings and their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: -1780.95367, std: 946.92422, params: {'alpha': 1e-10, 'fit_intercept': True}, mean: -1781.84322, std: 946.91796, params: {'alpha': 1e-10, 'fit_intercept': False}, mean: -1780.95367, std: 946.92422, params: {'alpha': 1.0000000000000001e-09, 'fit_intercept': True}, mean: -1781.84322, std: 946.91796, params: {'alpha': 1.0000000000000001e-09, 'fit_intercept': False}, mean: -1780.95367, std: 946.92422, params: {'alpha': 1e-08, 'fit_intercept': True}, mean: -1781.84322, std: 946.91796, params: {'alpha': 1e-08, 'fit_intercept': False}, mean: -1780.95367, std: 946.92422, params: {'alpha': 9.9999999999999995e-08, 'fit_intercept': True}, mean: -1781.84322, std: 946.91796, params: {'alpha': 9.9999999999999995e-08, 'fit_intercept': False}, mean: -1780.95367, std: 946.92423, params: {'alpha': 9.9999999999999995e-07, 'fit_intercept': True}, mean: -1781.84322, std: 946.91796, params: {'alpha': 9.9999999999999995e-07, 'fit_intercept': False}, mean: -1780.95367, std: 946.92423, params: {'alpha': 1.0000000000000001e-05, 'fit_intercept': True}, mean: -1781.84321, std: 946.91798, params: {'alpha': 1.0000000000000001e-05, 'fit_intercept': False}, mean: -1780.95365, std: 946.92431, params: {'alpha': 0.0001, 'fit_intercept': True}, mean: -1781.84317, std: 946.91811, params: {'alpha': 0.0001, 'fit_intercept': False}, mean: -1780.95344, std: 946.92506, params: {'alpha': 0.001, 'fit_intercept': True}, mean: -1781.84272, std: 946.91942, params: {'alpha': 0.001, 'fit_intercept': False}, mean: -1780.95142, std: 946.93253, params: {'alpha': 0.01, 'fit_intercept': True}, mean: -1781.83823, std: 946.93260, params: {'alpha': 0.01, 'fit_intercept': False}, mean: -1780.93412, std: 947.00328, params: {'alpha': 0.10000000000000001, 'fit_intercept': True}, mean: -1781.79342, std: 947.06423, params: {'alpha': 0.10000000000000001, 'fit_intercept': False}, mean: -1780.76191, std: 947.68463, params: {'alpha': 1.0, 'fit_intercept': True}, mean: -1781.35332, std: 948.37278, params: {'alpha': 1.0, 'fit_intercept': False}, mean: -1778.95714, std: 954.59113, params: {'alpha': 10.0, 'fit_intercept': True}, mean: -1777.68142, std: 960.74659, params: {'alpha': 10.0, 'fit_intercept': False}, mean: -1785.01406, std: 1012.70700, params: {'alpha': 100.0, 'fit_intercept': True}, mean: -1779.45750, std: 1045.56524, params: {'alpha': 100.0, 'fit_intercept': False}, mean: -2077.30726, std: 1196.45211, params: {'alpha': 1000.0, 'fit_intercept': True}, mean: -2062.70502, std: 1291.01789, params: {'alpha': 1000.0, 'fit_intercept': False}, mean: -2452.98681, std: 1296.72941, params: {'alpha': 10000.0, 'fit_intercept': True}, mean: -2558.65616, std: 1708.14172, params: {'alpha': 10000.0, 'fit_intercept': False}, mean: -2543.16948, std: 1316.15366, params: {'alpha': 100000.0, 'fit_intercept': True}, mean: -3362.36212, std: 2190.32474, params: {'alpha': 100000.0, 'fit_intercept': False}, mean: -2554.64498, std: 1318.43312, params: {'alpha': 1000000.0, 'fit_intercept': True}, mean: -3661.92482, std: 2304.70846, params: {'alpha': 1000000.0, 'fit_intercept': False}, mean: -2555.83113, std: 1318.66537, params: {'alpha': 10000000.0, 'fit_intercept': True}, mean: -3699.37449, std: 2317.65123, params: {'alpha': 10000000.0, 'fit_intercept': False}, mean: -2555.95015, std: 1318.68864, params: {'alpha': 100000000.0, 'fit_intercept': True}, mean: -3703.21133, std: 2318.96221, params: {'alpha': 100000000.0, 'fit_intercept': False}, mean: -2555.96206, std: 1318.69096, params: {'alpha': 1000000000.0, 'fit_intercept': True}, mean: -3703.59596, std: 2319.09348, params: {'alpha': 1000000000.0, 'fit_intercept': False}, mean: -2555.96325, std: 1318.69120, params: {'alpha': 10000000000.0, 'fit_intercept': True}, mean: -3703.63443, std: 2319.10661, params: {'alpha': 10000000000.0, 'fit_intercept': False}]\n"
     ]
    }
   ],
   "source": [
    "print gs.grid_scores_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "\tcurrent distance 6.2\n",
      "\tdistance 5.2 is better than 6.2\n",
      "\tfound better solution! using 5.2\n",
      "iteration 1\n",
      "\tcurrent distance 5.2\n",
      "\tdistance 4.2 is better than 5.2\n",
      "\tfound better solution! using 4.2\n",
      "iteration 2\n",
      "\tcurrent distance 4.2\n",
      "\tdistance 3.2 is better than 4.2\n",
      "\tfound better solution! using 3.2\n",
      "iteration 3\n",
      "\tcurrent distance 3.2\n",
      "\tdistance 2.2 is better than 3.2\n",
      "\tfound better solution! using 2.2\n",
      "iteration 4\n",
      "\tcurrent distance 2.2\n",
      "\tdistance 1.2 is better than 2.2\n",
      "\tfound better solution! using 1.2\n",
      "iteration 5\n",
      "\tcurrent distance 1.2\n",
      "\tdistance 0.2 is better than 1.2\n",
      "\tfound better solution! using 0.2\n",
      "iteration 6\n",
      "\tcurrent distance 0.2\n",
      "6.0 is closest to 6.2\n"
     ]
    }
   ],
   "source": [
    "num_to_approach = 6.2\n",
    "start = 0.\n",
    "steps = [-1, 1]\n",
    "optimized = False\n",
    "a=0\n",
    "while not optimized:\n",
    "    print 'iteration', a\n",
    "    current_distance = num_to_approach - start\n",
    "    print '\\tcurrent distance', current_distance\n",
    "    got_better = False\n",
    "    next_steps = [start + i for i in steps]\n",
    "    for n in next_steps:\n",
    "        distance = np.abs(num_to_approach - n)\n",
    "        if distance < current_distance:\n",
    "            got_better = True\n",
    "            print '\\tdistance', distance, 'is better than', current_distance\n",
    "            current_distance = distance\n",
    "            start = n\n",
    "    if got_better:\n",
    "        print '\\tfound better solution! using', current_distance\n",
    "        a += 1\n",
    "    else:\n",
    "        optimized = True\n",
    "        print start, 'is closest to', num_to_approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Bonus: \n",
    "implement a stopping point, similar to what n_iter would do in gradient descent when we've reached \"good enough\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Application of Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent R2: 0.308539257363\n",
      "Gradient Descent MSE: 1680.83467776\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.SGDRegressor()\n",
    "lm.fit(modeldata, y)\n",
    "print \"Gradient Descent R2:\", lm.score(modeldata, y)\n",
    "print \"Gradient Descent MSE:\", metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check: Untuned, how well did gradient descent perform compared to OLS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Practice: Bike data revisited\n",
    "\n",
    "There are tons of ways to approach a regression problem. The regularization techniques appended to ordinary least squares optimizes the size of coefficients to best account for error. Gradient Descent also introduces learning rate (how aggressively do we solve the problem), epsilon (at what point do we say the error margin is acceptable), and iterations (when should we stop no matter what?)\n",
    "\n",
    "For this deliverable, our goals are to:\n",
    "\n",
    "- implement the gradient descent approach to our bike-share modeling problem,\n",
    "- show how gradient descent solves and optimizes the solution,\n",
    "- demonstrate the grid_search module!\n",
    "\n",
    "While exploring the Gradient Descent regressor object, you'll build a grid search using the stochastic gradient descent estimator for the bike-share data set. Continue with either the model you evaluated last class or the simpler one from today. In particular, be sure to implement the \"param_grid\" in the grid search to get answers for the following questions:\n",
    "\n",
    "- With a set of alpha values between 10^-10 and 10^-1, how does the mean squared error change?\n",
    "- Based on the data, we know when to properly use l1 vs l2 regularization. By using a grid search with l1_ratios between 0 and 1 (increasing every 0.05), does that statement hold true? If not, did gradient descent have enough iterations?\n",
    "- How do these results change when you alter the learning rate (eta0)?\n",
    "\n",
    "**Bonus**: Can you see the advantages and disadvantages of using gradient descent after finishing this exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_model.SGDRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST ESTIMATOR\n",
      "1689.7527876\n",
      "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "ALL ESTIMATORS\n",
      "[mean: -1689.75279, std: 53.67508, params: {}]\n"
     ]
    }
   ],
   "source": [
    "params = {} # put your gradient descent parameters here\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.SGDRegressor(),\n",
    "    cv=cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True),\n",
    "    param_grid=params,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    )\n",
    "\n",
    "gs.fit(modeldata, y)\n",
    "\n",
    "print 'BEST ESTIMATOR'\n",
    "print -gs.best_score_\n",
    "print gs.best_estimator_\n",
    "print 'ALL ESTIMATORS'\n",
    "print gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## go for it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
